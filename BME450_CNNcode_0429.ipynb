{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns  # For a nicer confusion matrix visualization\n",
    "#Test data visualization\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "\n",
    "# Device configuration (choose CPU/GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available()else 'cpu')\n",
    "print(device)\n",
    "# Here, using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter\n",
    "batch_size = 60\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 15\n",
    "trainingEpoch_loss = []\n",
    "validationEpoch_loss = []\n",
    "trainingEpoch_accuracy = []\n",
    "validationEpoch_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images\n",
    "    transforms.ToTensor(),  # Convert images to Tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n",
    "])\n",
    "\n",
    "# Create dataset instances\n",
    "dataset = datasets.ImageFolder(root='D:/Purdue/2024 Spring/BME 450/Project/Data_mix', transform=transform)\n",
    "\n",
    "#Given categoreis\n",
    "categories = ('glioma','meningioma','notumor','pituitary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset\n",
    "num_train, num_val,num_test = 0.8*len(dataset), 0.1*len(dataset),0.1*len(dataset)\n",
    "num_train = int(num_train)\n",
    "num_val = int((num_val) + 1)\n",
    "num_test = int(num_test)\n",
    "\n",
    "trainset,valset,test_dataset = torch.utils.data.random_split(dataset,[num_train, num_val,num_test])\n",
    "len(trainset), len(valset), len(test_dataset)\n",
    "\n",
    "\n",
    "print(f'The traning data set size is {len(trainset)}\\nThe size validate dataset is {len(valset)}\\nThe size of test dataset is {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataloader\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Version of model\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels= 8, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels= 16, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels= 32, kernel_size=3)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features = 32*26*26,out_features=120) # num of feature * size * size\n",
    "        #self.drop1 = nn.Dropout(p = 0.3)\n",
    "\n",
    "\n",
    "        self.out = nn.Linear(in_features=120, out_features = 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.pool1(x))\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.pool2(x))\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.pool3(x))\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = self.drop1(x)\n",
    "\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model, loss function, and optimizer\n",
    "model = ConvNet().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss() # If do not end with softmax, use this\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) #stochastic gradient descent --> Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "def train_one_epoch():\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    trainingEpoch_loss.append(np.array(epoch_loss))\n",
    "    trainingEpoch_accuracy.append(np.array(epoch_accuracy))\n",
    "    print(f'Training Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "def validate_one_epoch():\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    validationEpoch_loss.append(np.array(epoch_loss))\n",
    "    validationEpoch_accuracy.append(np.array(epoch_accuracy))\n",
    "    print(f'Validation Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "    print('***************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CNN\n",
    "for epoch_index in range(num_epochs):\n",
    "    print(f'Epoch: {epoch_index + 1}\\n')\n",
    "    \n",
    "    train_one_epoch()\n",
    "    validate_one_epoch()\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot training history\n",
    "Epochs = [i+1 for i in range(len(trainingEpoch_accuracy))]\n",
    "print(len(Epochs))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(Epochs,trainingEpoch_loss, label='Tranining Loss')\n",
    "plt.plot(Epochs,validationEpoch_loss,label='Validated Loss')\n",
    "plt.legend()\n",
    "\n",
    "print(len(trainingEpoch_accuracy))\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(Epochs,trainingEpoch_accuracy, label='Tranining Accuracy')\n",
    "plt.plot(Epochs,validationEpoch_accuracy,label='Validated Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "# Lists to store all labels and predictions\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        # Get output\n",
    "        outputs = model(images)\n",
    "        # Choose prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # Append labels\n",
    "        all_labels.extend(labels)\n",
    "        all_predictions.extend(predicted)\n",
    "\n",
    "# Convert lists into tensors for confusion matrix computation\n",
    "all_labels = torch.stack(all_labels).cpu().numpy()\n",
    "all_predictions = torch.stack(all_predictions).cpu().numpy()\n",
    "\n",
    "print(f'Accuracy of the network on the 1310 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predictions, labels = range(len(categories)))\n",
    "print(cm)\n",
    "# Plotting the confusion matrix\n",
    "sns.heatmap(cm, fmt='d', cmap='Blues',xticklabels=categories, yticklabels=categories)\n",
    "#sns.heatmap(cm, annot= True, fmt='d', cmap='Blues',xticklabels=categories, yticklabels=categories,annot_kws={\"size\": 12})   \n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "#plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random 12 figures\n",
    "num_samples = 12\n",
    "indices = torch.randperm(len(test_dataset))[:num_samples]\n",
    "sampler = SubsetRandomSampler(indices)\n",
    "test_loader_plot = DataLoader(test_dataset, batch_size=num_samples, sampler=sampler)\n",
    "\n",
    "# Get one batch of data\n",
    "images, labels = next(iter(test_loader_plot))\n",
    "\n",
    "# Move the batch to the same device as the model\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Plot the results\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "axes = axes.ravel()\n",
    "for i, (img, label, pred) in enumerate(zip(images.cpu(), labels.cpu(), predicted.cpu())):\n",
    "    img_pil = to_pil_image(img)  # Convert tensor to PIL Image\n",
    "    axes[i].imshow(img_pil)\n",
    "    axes[i].set_title(f'True: {categories[label]}\\nPred: {categories[pred]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
